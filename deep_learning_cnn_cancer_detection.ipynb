{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwlZkcWkuGMD"
      },
      "source": [
        "# Deep Learning: CNN: Cancer Detection\n",
        "**Thomas Bohn**   --   **2025-09-14**\n",
        "\n",
        "{{xxxxx}}  \n",
        "\n",
        "--  [Main Report](xxxx)  --  [Github Repo](xxxx)  --  [Presentation Slides](xxx)  --  [Presentation Video](xxx) --  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07lWDJH6vAuV"
      },
      "source": [
        "# 1.&nbsp;Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHhIXdBPvCDs"
      },
      "source": [
        "**Problem Statement**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Why is it Important?**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Limitations of Existing Solutions**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Contribution**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**DataSet**\n",
        "\n",
        "{{xxxxx}}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9augt6L_Wnb"
      },
      "source": [
        "## Python Libraries\n",
        "\n",
        "The following python libraries are used in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pjoVn_82_Rya"
      },
      "outputs": [],
      "source": [
        "# File system manangement\n",
        "import time, datetime, psutil, os\n",
        "\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Install text storage and manipulation\n",
        "import re\n",
        "import json\n",
        "import pickle\n",
        "import textwrap\n",
        "\n",
        "#Install Image processing\n",
        "from PIL import Image\n",
        "\n",
        "##################################\n",
        "\n",
        "# Plotting and visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "\n",
        "# Train-test split and cross validation\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#################################\n",
        "\n",
        "# Import Tensor Flow and Keras\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, models\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y39B3sJjvTD1"
      },
      "source": [
        "## Global Variables\n",
        "\n",
        "The following are global variables referenced in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vfjyMW6K_SS-"
      },
      "outputs": [],
      "source": [
        "# Recording the starting time, complemented with a stopping time check in the end to compute process runtime\n",
        "start = time.time()\n",
        "\n",
        "# Class representing the OS process and having memory_info() method to compute process memory usage\n",
        "process = psutil.Process(os.getpid())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLiPgQzL-Oiu",
        "outputId": "37b24a0d-e121-44be-ef66-da4bc270dc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level of Detail for functions is set to: 2\n"
          ]
        }
      ],
      "source": [
        "# Global Debug flag used to turn on and off more chatty blocks of code\n",
        "gDEBUG = False\n",
        "if gDEBUG: print('Debug is set to:', gDEBUG)\n",
        "# Global Level of Detail of table stats and details\n",
        "gLOD = 2\n",
        "print('Level of Detail for functions is set to:', gLOD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnEP1IbB-1dF"
      },
      "source": [
        "# 2.&nbsp;Data Source\n",
        "\n",
        "In this section, the code loads the dataset from Google Drive.\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E54ZVhqGH0o1"
      },
      "source": [
        "## Import the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s47OY0wa-9VR",
        "outputId": "73c66d41-1e90-4c72-dd74-eecd25769ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path_root =  '/content/drive/MyDrive/[1.4] MsDS Class Files/-- DTSA 5511 Deep Learning/data'\n",
        "\n",
        "file_path_train   = file_path_root + '/train'\n",
        "file_path_test    = file_path_root + '/test'\n",
        "file_path_labels  = file_path_root + '/train_labels.csv'\n",
        "file_path_sample  = file_path_root + '/sample_submission.csv'\n",
        "\n",
        "# Load train labels from CSV file\n",
        "train_labels = pd.read_csv(file_path_labels)\n",
        "\n",
        "# Load test labels from CSV file\n",
        "sample_output = pd.read_csv(file_path_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr1LwEFwAUTh"
      },
      "outputs": [],
      "source": [
        "if gDEBUG:\n",
        "  # Preview the Data Sources\n",
        "  print(\"Sample of Training Labels\")\n",
        "  display(train_labels.head(5))\n",
        "  print()\n",
        "  print(\"Sample of Results Output:\")\n",
        "  display(sample_output.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get training and testing files\n",
        "train_file_names = os.listdir(file_path_train)\n",
        "test_file_names = os.listdir(file_path_test)\n",
        "\n",
        "print(\"Total Training Files: \", len(train_file_names))\n",
        "print(\"Total Testing Files: \", len(test_file_names))\n",
        "pct_assigned_train = round(len(train_file_names) / (len(train_file_names) + len(test_file_names)), 3)\n",
        "print(\"Percent Assigned to Training:\" pct_assigned_train)\n",
        "\n",
        "\n",
        "print('Preview of training image file names: ')\n",
        "print(train_file_names[:10])\n",
        "print('Preview of testing image file names: ')\n",
        "print(test_file_names[:10])"
      ],
      "metadata": {
        "id": "pnOHkX8Mb_5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bhQNlmlbcKpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JAv-COuvtIa"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFQE7rB8WVYq"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SDhEs0dwHtb"
      },
      "source": [
        "## Address Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwlHSmjPFHl4"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV3brMgOMPMc"
      },
      "source": [
        "## Data Scoping Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxtyPl_7WVYr"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTPr0Xs6Hv8t"
      },
      "source": [
        "## Scope the Label and Text for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t57JY7XRWVYr"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BtBwi2SKW2N"
      },
      "source": [
        "# 3.&nbsp;Exploratory Data Analysis (EDA)\n",
        "\n",
        "The EDA phase focuses on understanding the dataset, including data distribution and label counts. Various functions are used to inspect the structure of the dataset, visualize the label distribution, and assess the text length and word count of the documentation. The data is found to be somewhat imbalanced across categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcwHYK4SI7wY"
      },
      "source": [
        "## EDA Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js5bd9jCWVYr"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bO3CvKfI_eC"
      },
      "source": [
        "## EDA Analysis: Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZVsvL8HWVYs"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKqQq5X1yCDw"
      },
      "source": [
        "## EDA Analysis: Text Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpiGLTRLWVYs"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SnbCeUGydTo"
      },
      "source": [
        "## EDA Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpqY9vM_yefS"
      },
      "source": [
        "ADD HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_4RFPD2fkeh"
      },
      "source": [
        "# 4.&nbsp;Train-Validation-Test Split\n",
        "\n",
        "Split the dataset into training, validation, and test sets. Use tratified splitting to ensure that the class distribution remains consistent across these sets. The distribution of records across the labels is visualized to ensure a balanced split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ctkj7jNx4B"
      },
      "source": [
        "## Test Split Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krcLqt3CWVYs"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT6-MV_PN1CC"
      },
      "source": [
        "## Test Split Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4oI-LXiWVYt"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3xCg6WhgqXI"
      },
      "source": [
        "# 5.&nbsp;Data Cleansing & Text Normalization\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap4Hw4S8Jd3E"
      },
      "source": [
        "## Core Normalization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDvwmmc2WVYt"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gZaDQqdJoe_"
      },
      "source": [
        "## Apply Text Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IrLYkcYWVYt"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm-_DGFFmuSv"
      },
      "source": [
        "# 6.&nbsp;Feature Engineering with TF-IDF\n",
        "\n",
        "The TfidfVectorizer from scikit-learn is used to convert the text documents into numerical features. The vectorizer transforms the collection of documents into a matrix of token counts, which is then normalized using the Term Frequency-Inverse Document Frequency (TF-IDF) transformation. This matrix representation of the text data serves as input to the machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWadgSEmJy8W"
      },
      "source": [
        "## TF_IDF Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcrvDNxJWVY6"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSsaEBx0a_L"
      },
      "source": [
        "## Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkFExD_QWVY6"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrJc1ZCi0IVf"
      },
      "source": [
        "# 7.&nbsp; Baseline Models: Supervised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO9FkdrHJ5US"
      },
      "source": [
        "## Model Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXZYwBtfWVY6"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eMVteAb01Vs"
      },
      "source": [
        "## Build, Train, and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGer3gOcWVY7"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0vP9xMCnepL"
      },
      "source": [
        "# 8.&nbsp; Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pYPbH5L1bjZ"
      },
      "source": [
        "## Tuning Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJdvJl_kWVY7"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtxev-Ul1pX9"
      },
      "source": [
        "## Execute Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWuUu-fNWVY7"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qsNOvyUoeyj"
      },
      "source": [
        "# 9.&nbsp;Final Prediction and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka8gqTlWKIl_"
      },
      "source": [
        "## Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yml8m7HWVY8"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II9qX_tf2LSL"
      },
      "source": [
        "## Train the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbRCnYpFWVY8"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DueXwork2PiL"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG84Vs5RWVY8"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CQ4nuAfqRJA"
      },
      "source": [
        "## Explore Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Rk4bwOfWVY9"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSKrlnc92lEz"
      },
      "source": [
        "# 10.&nbsp;Scale the Auto-Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZDLjLP53aIq"
      },
      "source": [
        "## Auto-Classifier Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6SCMGkkWVY9"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad5blW7Os2iX"
      },
      "source": [
        "## Rerun Process for L1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9uA9ScVWVY9"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhOtlzh0jGGe"
      },
      "source": [
        "## Rerun Process for L2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlNYEGWZWVY-"
      },
      "outputs": [],
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWv340Xx265l"
      },
      "source": [
        "# 11.&nbsp; Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuHSlWe-O-br"
      },
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNzNW_nH37_9"
      },
      "source": [
        "## Results Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld4AlXnnWVY-"
      },
      "source": [
        "### Model Result Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YlcWEw_8Bp-"
      },
      "source": [
        "\n",
        "**Baseline Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Hyperparameter Tuning Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Best Model Results**\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "**Best Model Performance**\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEQfc7PI38Tq"
      },
      "source": [
        "## Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql8QLBc2LoEy"
      },
      "source": [
        "### Model Comparisons and Findings\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Baseline Results\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Hyperparameter Tuning\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Best Model Results\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Performance Breakdown (Best Model)\n",
        "\n",
        "{{xxxxx}}\n",
        "\n",
        "#### Conclusion\n",
        "\n",
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlXB6itm4D4r"
      },
      "source": [
        "## Concluding Observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGbGMDoNOr-w"
      },
      "source": [
        "## Patterns and Conclusions Across the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ofvfgBOsLZ"
      },
      "source": [
        "{{xxxxx}}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rb2X9yUX4FOn"
      },
      "source": [
        "# 12.&nbsp; References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq8tcmLa4FXR"
      },
      "source": [
        "**Kaggle Competition**\n",
        "\n",
        "- [1] Thomas Bohn. 2024. sfdc_help_site_scrape.ipynb. https://github.com/TOM-BOHN/MsDS-supervised-nlp-sfdc-auto-classification/blob/main/sfdc_help_site_scrape.ipynb\n",
        "\n",
        "**Documentation and References**\n",
        "\n",
        "- [2] Wikipedia Contributors. 2024. Tf-idf. In Wikipedia. https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
        "\n",
        "**Data Source**\n",
        "\n",
        "- [13] Salesforce. 2024. Salesforce Winter ’25 Release Notes. In Salesforce Help. https://help.salesforce.com/s/articleView?id=release-notes.salesforce_release_notes.htm&release=216&type=5"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "r9augt6L_Wnb",
        "6BtBwi2SKW2N"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}